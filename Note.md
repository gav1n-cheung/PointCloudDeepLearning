# 点云数据深度学习

# 分类、分割和特征提取

以往的针对点云的数据的深度学习方法主要有两种：

* 由于常见的二维图像深度学习方法已经非常完善了，其基于卷积的深度学习方法已经得到了非常多的应用了。因此可以将点云数据投影到二维平面上去，再使用二维的方法进行分类/分割等任务；这种方式使用的投影方向多为前视视角和鸟瞰视角；而且可以融合使用来自相机的图像信息。通过这些不同视角得到的数据相结合，来实现点云数据的认知任务。比较经典的算法有==MV3D==和==AVOD==
* 卷积操作适用于具有空间依赖关系的数据，因此可以将点云转换为具有明确拓扑关系的体素，再使用3D卷积等方式进行处理。这种方法缺陷在于，如果划分分辨率较大的体素网格，则导致大量的空间无点云数据也占据了极大的空间，如果划分较小的分辨率，则导致细节的丢失。这种处理方式



|        | 分类准确性 | 主要思想                                                     | 创新点/解决的关键问题                                        | 缺点                                                         |
| ------ | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| VoxNet | 84%        | （三维卷积）通过体素来构建空间结构，从而便于进行3维卷积      |                                                              | 体素分辨率过低，拓展性不足；体素化了大量无信息的空间，浪费资源 |
| MVCNN  | 90%        | （二维投影）通过投影获得2D图像，迁移学习预训练模型，在进行模型微调从而识别3维物体 | 如何将多张二维视图进行融合，这里使用的是一个view  pooling，对所有的模型的同一个位置取其最大值，效果优秀 | 在imageNet上预训练模型就是一个很大的不足；对每个投影进行训练也耗费很大资源，迁移性较差 |



## 1：VoxNet

### 1.1：创新点

在本文中，我们提出了一种voxNet，一个通过集成体积占用网格表示和监督的3D卷积神经网络(3D CNN)来解决大量点云数据的处理问题。

### 1.2：相关工作

#### 1.2.1：点云数的目标识别

​		在利用激光雷达和RGBD传感器生成的3D点云进行目标识别方面有大量的工作。大多数工作利用管道将各种手工制作的特征或描述子与机器学习分类器组合在一起。语义分割的情况与之类似，使用结构化输出分类器而非单个输出分类器。==与这些方法不同，我们的架构通过原始的体素数据学会了提取特征并对对象进行分类==。提速表示也比点云数据更为丰富，因为其区分了自由空间和未知空间。此外，==基于点云的特征通常需要空间邻域查询，这在大量点的情况下会很快变得难以处理（点云的无序性）==。

#### 1.2.2：2.5D卷积神经网络

​		一些工作将CNN拓展到RGBD数据上，这些方法只是将深度通道作为一个附加通道以及RGB通道。这些方法虽然简单，但是没有充分利用数据中的几何信息，使得跨视点的信息集成变得困难。

​		对于LiDAR，前人提出了一个特性，该特性使用2.5D表示局部描述子，也有人研究了这种方法，并结合了一种无监督的特征学习形式。但是这些工作仍然以2D为中心。

​		而我们的工作采用了一种完整的立体表示，从而使环境的表现更加丰富区分度也更高。

#### 1.2.3：3D卷积神经网络

​		具有立体性(即空间3D)卷积的架构已经成功用于视频分析。在这种情况下，时间充当了第三维度。从算法原理上讲，这些工作的本质与我们的相同，但是数据的本质却截然不同。

​		在RGBD领域中，使用无监督体积特征学习方法作为管道的一部分来检测室内物体。这种方法基于稀疏编码，通常比卷积模型慢。在并行工作中，有人提出了一个生成的三维卷积模型的形状，并将其应用于RGBD对象识别等任务。我们与之进行了比较。

​		在激光雷达领域，有前人研究了3D CNN使用激光雷达数据应用于二分类问题。

### 1.3：主要内容

​		本文的算法输入的是一个点云段，它可以来自于分割方法，如果执行检测，也可以是一个滑动框。点云段通常由点云与包围盒的交集给出，有可能会包括背景噪声。我们的任务是预测点云段的对象类标签。用于该任务的系统有两个主要组件：一个表示我们对空间结构表征的占用网格，以及一个直接从网格预测类标签的3D CNN。

#### 1.3.1：体积占用网格

​		占用网格将环境状态表示为随机变量的三维网格(每个都对应一个体素)，并且更具输入的传感器数据和先验知识保持对其占用率的概率估计。

​		==使用占用网格的主要原因为：==

	1.  它使得我们可以从距离测量中有效的估计自由、被占用和未知空间，深度可以从不同的角度和时间进行实时测量。这种表示比那些只考虑已占空间和自由空间(如点云)的表示更为丰富，因为自由空间和未知空间之间的区别可能是一个有价值的形状线索。
	2.  其次，他们可以用简单有效的数据结构进行存储和操作。在这项工作中，我们使用密集数组来执行所有的CNN处理

#### 1.3.2：参考坐标系和分辨率

​		在我们的体积表示中，每个点(x,y,z)被映射到离散体素坐标(i,j,k)。映射是一个均匀的离散化，但取决于体素网格在空间中的远点、方向和分辨率。体素化对象的出现在很大程度上取决于这些参数。

* 对于原点，我们假设它是作为一个输入给出的，例如通过分割算法得到的或者通过滑动框给出的。
* 对于方向，我们假设网格框架的轴线近似地与重力方向对齐。这可以通过一个IMU或者保持传感器直立来实现。
* 现在还有一个自由度--绕轴旋转(偏航)。如果我们为每一个对象定义一个规范的方向，并且能够自动检测这个方向，那么总是将网格对齐到这个方向是合理的。然而，在实践中，从稀疏和有噪声的点云中检测出这个方向是复杂的。在本文中，我们提出了一种基于数据增强的简单替代方案。

#### 1.3.3：占用率模型

​		假设{z^t^}^T^~t=1~是一个距离测量序列，该序列一定击中(z^t^=1)或穿过(z^t^=0)一个坐标为(i,j,k)的给定体素。假设一个理想的波束传感器模型，我们使用3D射线跟踪计算每个体素的击中和穿过的次数。

​		有了这些信息，我们考虑了三种不同的占用网格模型来估计勇战：二元占用网格。在这个模型中，假设每个体素都有一个二元状态--被占用或不被占用。为保证数据稳定性，每个体素占用率的概率估计使用对数概率计算的。

#### 1.3.4：3D卷积网络层

​		对于我们的任务，CNN是一个较好的选择，主要原因有三：

* 可以充分利用前面构建的空间结构，特别是CNN可以学习对分类任务有用的局部空间滤波器。在我们的例子中，我们期望输入层的过滤器编码空间结构，如不同方向的平面和角。
* 通过叠加多层，网络可以构建一个更加复杂的特征层次结构，代表更大的空间区域，最终使得输入占用网格的全局标签。
* 推理是前馈的，可以在普通图形硬件上高效执行。

​		对于我们的任务，定义网络结构如下：

![image-20211209175934211](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211209175934211.png)

* 输入层：该层接受一个固定大小的I * j * K的体素网格输入，这里我们使用的是32* 32 *32的输入，根据占用模型，每个网格单元的值都将更新。
* 卷积层：这些层接受四维输入体，其中三个维度是空间的，第四个维度为包含特征映射。该层通过将输入与shaped * d * d *f0的过滤器进行卷积来创建特征映射，其中d为空间维度，f0是输入特征映射的数量。输出通过一个参数为0.1的ReLU的激活函数保持非线性化。
* 池化层：这些层通过将每个非重叠体素替换为他们的最大值，在空间维度上对输入体积采样m倍。
* 全连接层：每个神经元的输出是前一层所有输出的学习线性组合，通过一个非线性层。除了最后的输出层，我们都是用ReLU。其中输出的数量对应于类标签的数量，并且使用softmax非线性来提供概率输出。
* voxnet在model40上的识别率大概在83%左右

### 1.4：性能

分辨率很低，以论文中32 * 32 *32为例，分辨率极低，在自动驾驶场景中完全无法使用，但其有一定的开创性。

## 2：MVCNN

### 2.1：创新点

3D形状用于识别的表示方法有：

* 操作其原生3D格式(如体素网格或多边形)描述子来表示
* 基于视图的描述子来表示

在本文中解决了该问题，在一个集合2D图像来识别三维形状。

首先，我们展示了一个经过训练的标准CNN架构，以识别目标的各自独立的渲染视图，并且展示一个3D形状，从单个图像识别的精度也远远高于使用最先进的3D形状描述子。当提供多个形状视图时，识别率进一步提高。

此外，我们提出了一种新颖的CNN架构，他将来自3D形状的多个视图的信息组成成了一个单一并且紧凑的形状描述子，提供了更好的识别性能。

我们的结论是，2D视图的集合可以为3D形状识别提供高度的信息，并且适用于新型的CNN架构及其衍生架构。

### 2.2：相关工作

#### 2.2.1：形状描述子

形状描述子可以分为两大类：

* 直接用于对象的原生3D表示的三维形状描述子，如多边形网格、基于体素的离散化、点云或隐式表面
* 基于视图的的描述子，通过2D投影集合中的"外观"来描述3D对象的形状

##### 2.2.1.1：基于三维形状描述子

有前人工作通过三维卷积从基于体素的物体表示学习形状描述子，以前的3D形状描述子大多是根据形状表面或体积的特定几何属性"手工设计"的。例如：形状可以用直方图或者特征包围模型来表示。

在3D形状描述子的基础上开发分类器和其他的有监督的机器学习算法带来了许多挑战。

* 首先，与图像数据集相比，带注释的3D模型的组织数据库的大小相当有限，与现有的2维数据库相比小的多
* 其次，3D形状描述子维度经常会非常高，使得分类器容易因为所谓的"维数灾难"而过拟合。（维数越高，则越可以描述我们想要的模型，但是也需要更多的数据，如果数据不够多，则很容易导致过拟合）

##### 2.2.1.2：基于视图的描述子

基于视图的描述子有许多可取的特性，它们是相对低维的、高效的评估，并且对三维形状表示更为鲁棒（例如可能的孔洞、不完美的多边形网格、噪声表面）。渲染的形状视图也可以直接与其他2D图像、剪影甚至手绘草图进行比较。

#### 2.2.2：卷积神经网络

本文中的多视图CNN架构学习使用基于图像的CNN从形状的视图中识别3D形状，但多个结构会通过视图池层，由此多个视图的信息有效地积累成一个单一的、紧凑的形状描述子。

### 2.3：主要内容

正如上文所讨论的，本文的重点是开发基于视图的3D形状描述子，这些描述子是可以训练的，为识别和检索任务生成信息表示，并且具有高效的计算性能。

我们的基于视图的表示是从一个3D形状的多个视图开始的，这些视图是由渲染引擎生成的。将多个视图融的一种简单方法是为每个视图生成一个2D图像描述子，然后根据某些投票或对齐方案直接将单个描述子用于识别任务。

最简单的方法是平均每个描述子，将所有视图是为同权重的。或者，如果视图以可重复的顺序呈现，还可以将所有视图的2D描述子连接起来。但是将一个3D形状对齐到一个规范的方向是困难的，有时是不明确的。

与以上提到的简单方法比起来，将多个视图的特征结合在一起的聚合表示更可取，因为它产生一个单一的，紧凑的描述子来表示3D形状。

我们的方法是学习使用一个统一的CNN架构，包括一个view pooling layer，将来自多个视图结合起来。本文的CNN架构所有参数都是有鉴别的学习，以产生一个单一的紧凑型描述子的三维形状，相比于对三维形状的单视图表示进行详尽的两两比较，我们得到的描述子可以直接用于比较三维形状，从而显著提高了计算效率。

#### 2.3.1：输入--多视图表示

为创建一个多视图形状表示，我们需要设置视点(虚拟相机)来渲染每个网格。在这个例子中，我们通过在网格周围每30度放置12个虚拟摄像机来创建12个渲染视图。这里的多个视图类似于二维图像中的数据增广，可以增加数据量并且增加模型的鲁棒性(CNN会自动学习获得变换不变性--旋转和平移不变性)。

<img src="C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211210161449043.png" alt="image-20211210161449043" style="zoom:150%;" />

#### 2.3.2：用多视图进行识别

在第一个设置中，我们直接利用现有的2D图像特征并为每个视图生成描述子，这是利用多视图表示的最直接的方法。然而，这样的处理会导致一个3D描述子有多个2D描述子，每个视图都有一个描述子，而我们需要将这些描述子以某种方式集成在一起，用于识别任务中。

##### 2.3.2.1：图像描述子

我们为每个2D视图考虑了两种类型的图像描述子：

* 基于Fisher向量和多尺度SIFT的最先进的"手工制作"图象描述子以及CNN激活特性。Fisher矢量图像描述子使用VLFeat来实现。对每幅图像密集提取多尺度SIFT描述子，使用PCA将他们投影到80个维度，然后使用64个成分的高斯混合模型、平方根和l2归一化的Fisher向量池
* 对于CNN，我们使用VGG-M网络，他主要由5个卷积层conv~1...5~，后接三个MLP fc~6..8~和softmax分类层，倒数第二层fc~7~(在ReLU非线性之后，4096维)作为图像描述子。网络在imageNet上进行预训练，然后再训练集中对3D形状的所有2D视图进行微调(可以显著提高性能)

与流程的3D形状描述子（如SPH和LFD）和3D ShapeNets相比，Fisher向量和CNN特征在分类和检索方面都有非常好的性能。

#### 2.3.3 MVCNN

我们的基于视图的表示是从一个3D形状的多个视图开始的，这些视图是由渲染引擎生成的。将多个视图融的一种简单方法是为每个视图生成一个2D图像描述子，然后根据某些投票或对齐方案直接将单个描述子用于识别任务。

最简单的方法是平均每个描述子，将所有视图是为同权重的。或者，如果视图以可重复的顺序呈现，还可以将所有视图的2D描述子连接起来。但是将一个3D形状对齐到一个规范的方向是困难的，有时是不明确的。

与以上提到的简单方法比起来，将多个视图的特征结合在一起的聚合表示更可取，因为它产生一个单一的，紧凑的描述子来表示3D形状。

我们的方法是学习使用一个统一的CNN架构，包括一个view pooling layer，将来自多个视图结合起来。本文的CNN架构所有参数都是有鉴别的学习，以产生一个单一的紧凑型描述子的三维形状，相比于对三维形状的单视图表示进行详尽的两两比较，我们得到的描述子可以直接用于比较三维形状，从而显著提高了计算效率。

如下面的网络结构，首先每个视图经过各自独立的经过第一段的CNN~1~，这些CNN的权值共享，在而再得到这些结果后，首先经过一个View pooling layer再进行CNN~2~,在View pooling层中，我们逐元素的取最大值。然后经过CNN~2~进行最后的分类任务。

![image-20211210181733790](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211210181733790.png)

### 2.4：性能

由于2D CNN的性能，分类识别率很高，但是由于投影操作太过耗费资源，使得迁移性很差。



## 3：OctNet

### 3.1：创新点

我们提出了OctNet，一种用于稀疏三维数据深度学习的表示。与现有模型相比，我们的表示方法使三维卷积网络既具有深度又具有高分辨率。为了实现这个目标，我们利用输入数据中的稀疏性，使用一组不平衡八叉树(每个叶节点存储一个机核的特征表示)分层的划分空间。这允许将内存分配和计算集中到相关的密集区域，并在不影响分辨率的情况下实现更深层次的网络。由于分辨率提高会带来内存和计算的负担，通常的体素分辨率是30^3^的，很显然不能表示足够的细节。

在这项工作中，我们基于这样的观察：3D数据在本质上通常是稀疏的，例如电云或者网格，在应用3D卷积时导致计算浪费。通过实验，我们得到结果--高激活只发生在物体边界附近。

基于这个观察，我们提出了OctNet，一个利用这种稀疏性的3D卷积网络。我们的OctNet分层的将3D空间划分为一组不平衡的八叉树，每个八叉树根据数据的密度分割三维空间。更具体的说，我们递归地分割包含域内数据点的八叉树节点。例如，3D点或网格三角形，停在树的最佳分辨率处。因此，叶节点的大小是不同的，例如，对于深度为3的树来说，一个空的叶节点可能包含8^3^=512个体素，八叉树中的每个叶节点存储了他所包含的体素的所有特征激活的汇总。卷积网络操作直接定义在这些树的结构上，因此，我们的网络根据输入的三维结构动态地集中计算和分配内存，这将大大减少计算和内存的需求，从而允许在高分辨率下进行深度学习。重要的是我们还展示了如何在这个新的数据结构上有效地实现基本的网络操作。

通过我们的OctNet，证明了更高的分辨率对方向估计和语义点云标记特别有益。

### 3.2 相关工作

### 3.3 主要内容

## 4：PointNet

### 4.1 绪论

与二维图像数据不同，3D数据有多种表达形式，可以是以下的几种：

![image-20211220153608731](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220153608731.png)

在这些数据格式中，我们认为点云是一种比较适合于3维场景理解的数据格式，原因有二：

* 点云是可以一种传感器直接获得的数据，是一种原始的数据类型，因此适用于端到端的模型，用于挖掘原始数据中的pattern(模式)
* 点云的表达形式是很简单的

![image-20211220154513753](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220154513753.png)

### 4.2 前期工作

首先有人想要在体素的表达形式上进行卷积提取特征，但是这种方式的时间复杂度和空间复杂度非常高，需要O(N^3^)，因此使用这种方式需要将体素分辨率设的很低，一般是30^2^这样的规模，相对于1000*800很常见的图像来说，分辨率过于低下了。而且噪声也会产生更大的影响。

如果我们不计复杂度的去提高体素的分辨率，会使得大部分的体素是空白的，我们扫描得到的都是表面的点，内部的空白体素没有意义，因此体素化预处理作为特征输入的方法不是最优的方法。

![image-20211220154708267](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220154708267.png)

也有人使用投影将点云投影到二维平面上去，然后用成熟的二维卷积来获取特征。但是这种方法会使得部分特征的丢失，而且如何投影，选择投影的方向，这不是一个像看起来那么简单的问题。

也有人使用手工提取的特征，然后去做全卷积，但这种方法使得网络性能受限于手工提取特征的局限性。

![image-20211220155238829](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220155238829.png)

### 4.3 主要内容

我们将点云表示为一个N*3的矩阵，如果我们随意的交换矩阵的行，即交换点，虽然矩阵会发生变化，但是点云其实是不变的，我们称之为点云的置换不变性。因此，我们的网络必须也要有这种特性。

![image-20211220162110612](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220162110612.png)

为解决这种问题，我们有一种系统的解决方法，即对称函数，比如max和加法操作。那如何让我们的网络具有这样的特性呢?

我们可以有这样的操作，比如输入一堆点，然后取最大值得到各个维度的最大值点，但是这样的操作使得点云的几何特征都丢失掉了。

![image-20211220162422670](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220162422670.png)

那我们先将点投影到高维空间上去，由于三维点投影到高维空间中他是冗余的，因此取最大值的时候可以因为他的冗余而避免数据的丢失，这样经过最大池化后的点可以尽可能地保留几何信息。再将信息经过一个gamma然后得到我们想要的特征。

![image-20211220163204770](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220163204770.png)

我们称这样地一个结构为PointNet vanilla

![image-20211220163257718](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220163257718.png)

这样我们就得到了这样的网络结构，我们将点不断地升维直至到达1024维然后经过对称地max pooling操作，得到一个1*1024的全局特征，再将其降维为分类的k维，最后使用交叉熵损失函数得到分类结果。期间使用一个T-Ne得到一个接近正交的矩阵T来旋转点云到正向的方向，并且将这个操作拓展到中间操作中。

![image-20211220164319606](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220164319606.png)

而对于分割任务，可以认为是对每个点进行分类。我们可以将n*64的局部特征和全局特征进行一个拼接，相当于在全局特征中对局部特征进行一个检索，来确定自己属于哪个类。然后对这个拼接后的特征作为全局特征，进行降维操作得到最后的n*m的向量，将点分类为m类，最后输出m个score.

![image-20211220165157797](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220165157797.png)

## 5：PointNet++

### 5.1 前期工作

我们拿3D卷积和PointNet做比较就会发现，由于卷积的原因，3D CNN有局部的特征和平移不变性，而PointNet其实一开始的一个点的特征或者全部点的特征。会对比较精细的特征学习有局限性，从而对分割问题有所影响。

而且平移不变性的缺失也会使得如果我们平移点云就会改变整个数据，从而改变分类结果。如果只有一个物体，我们可以对坐标进行归一化，但是对于多个物体的场景，我们就没法确定归一化的标准。

![image-20211220170450090](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220170450090.png)

### 5.2 主要内容

因此我们提出了一个想法，对局部使用PointNet来提取局部特征。

![image-20211220171141352](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220171141352.png)



举一个例子：我们以下图为例，我们提取N周围区域，为避免整体平移的影响，我们将这个小区域的点转换到一个局部坐标系中去，然后对其使用PointNet提取特征。

![image-20211220171317083](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220171317083.png)

然后得到了新的向量，这个向量有N的坐标信息(欧式空间中)和一个F(高维特征空间中)代表区域的几何特征。

![image-20211220171537080](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220171537080.png)

重复这个操作，就可以得到一些新的点，这些点的数量一般是少于原来的数据点，但是这些点有代表了其周围区域的几何特点。这些操作形成了一个layer，包括选择小区域、对小区域点的提取、选定局部坐标系和使用pointnet几个过程。

![image-20211220171933586](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220171933586.png)

我们可以重复这个layer，得到的点会越来越少，同时也会有更多的几何特征，类似于卷积中的感知域会变大，然后我们利用最后得到的特征点在做一个Pooling，得到全局特征，将其用于分类任务。

![image-20211220172218879](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220172218879.png)

我们也可以使用up-convolution将这些点传回原来的点上，up-convolution可以是基于3D插值，也可以是另一种基于PointNet的方法。然后得到每个点的成绩，用于分割任务。

![image-20211220172445981](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220172445981.png)

 在2D CNN中，有一种趋势是选择更小的卷积核，那在PointNet++中是否选择更小半径的球体来做局部的PointNet效果会更好呢？这是不一定的。==因为点云的分布是不均匀的，如果球体包含的点较少甚至只有一个点，那学习到的特征是十分不稳定的。==实验证明，如果我们选用较小的kernel，则会导致采样不均匀，随着点的减少，性能大幅下降，远远低于PointNet对于稀疏点的鲁棒性。

那我们就需要设计特殊的网络结构来解决这个问题，比如MSG这种选择不同kernel size来进行特征的融合。我们在输入时随机的dropout一些输入点，迫使网络去学习这种情况。

![image-20211220173835297](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220173835297.png)

实验证明这两种操作对点数量减少呈现了非常强的鲁棒性。

![image-20211220174242460](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220174242460.png)

由于多级网络结构，对于patial scans的效果提升很明显。

![c](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211220174213707.png)

点云和graph之间的关系，其实我们可以将点云看作是graph，只是他只有点，没有edge。但是在图形学中，点云跟图不太一样，因为点云确实是有shape info的。

## 6：SLAPNet

### 6.1 摘要

本文提出了一种用于处理点云的网络，该结构直接对高维体素中表示为稀疏样本集合的点云集合进行操作。随着体素尺寸的增加，很自然地，在网格上应用卷积会使得内存和计算成本的伸缩性很差。相反，我们的网络使用==稀疏的双边卷积==作为构建块，这些层通过索引结构仅在体素的占用部分应用卷积来保持效率，并且允许体素结构的领过规范，从而实现分层和空间感知特征学习以及2D-3D地联合推理。

基于点的或是基于图像的表示都可以很容易地合并到具有这些层的网络中，并且生成的模型可以以端到端的方式进行训练。

### 6.2 简介

点云由稀疏无序的三维点组成，这些特性使得传统卷积神经网络结构难以用于点云处理，因此，直接操作点云的现有方法主要由手工制作的特性所主导。

使用CNN进行点云操作的一种方法是将点云预处理为可以适应标准空间卷积的形式，这种处理方法通过视图投影点云成为二维图或者体素。因为CNN可以很容易地作用于二维或三维网格中，但是将点云进行这样的处理通常会得到不真实的结果，更重要的是，会丢失点云中存在的自然不变性。

而一些网络架构能够直接作用点云上，这些体系结构的一个主要缺点是他们不允许灵活地指定跨点(过滤邻域)的空间连接范围，而是全部使用最大池化来全局或者分层地跨点聚合信息。由于明确考虑点的空间分布，这种池聚合方式可能会丢失曲面信息。我们希望能够更通用的卷积运算捕获点云中的空间关系，同时能够以灵活方法指定过滤范围。

在这项工作中，我们提出了一种通用且灵活的神经网络结构用于处理点云，从而缓解了上述问题。==我们的主要结果是提出了双边卷积层(BCL)对点云处理有几个有利的特性。==BCL提供了一种过滤无序点的系统方法，同时规范支持卷积操作的底层晶格结构。BCL将输入点平滑地映射到稀疏晶格中，在稀疏晶格上执行卷积，然后将滤波后的信号平滑地插值回原始输入点。以BCL为建构部分，我们提出了一种新的神经网络结构，我们称之为SPLATNet(稀疏晶格网络)，它对无序点进行分层并对空间感知的特征进行学习。SPALTNet在点云处理中有几个优势：

* SPLATNet将点云作为输入，不需要做体素或者图像的预处理

* SPLATNet能够像CNN一样，轻松指定过滤器的邻域

* 通过使用哈希表，SPLATNet能够通过仅在存在数据的位置进行卷积从而有效地处理输入点云中的稀疏性

* SPLATNet使用稀疏高效的晶格过滤器计算输入点云的层次和空间感知特征

* SPLATNet架构允许将2D点轻松地映射到3D空间，反之亦然。在此基础上，我们提出了一种2D-3D联合深度架构，该架构在单次向前传递过程中处理多视图2D图像和相应的3D点云，同时具有端到端的可学习性。

  ![image-20220427144211238](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144211238.png)

### 6.3 相关工作

我们回顾现有的3D形状处理深度学习方法，并且解释与我们工作的不同之处

#### 6.3.1 多视图和体素网格

##### 6.3.1.1多视图

多视图网路将形状预处理为一组二维渲染图像，编码各种二维投影下的表面深度和法线。

*  这些网络得益于输入图像的高分辨率，并通过微调2D预训练的基于图像的架构来迁移学习。
*  另一方面，2D投影可能由于自遮挡而导致曲面信息丢失，而视点的选择通常是通过启发式进行的，对于给定的任务来说，启发式并不一定总是最优的。

##### 6.3.1.2 体素

基于体素的方法将输入的三维形状表示转换为三维体积网格。早期基于体素的体系结构在常规的固定的体素网格中执行卷积，由于内存和计算成本高，限制了使用的体素分辨率。

与前期的方法不同，最近的方法将输入形状预处理为自适应细分的分层网格，其中密集的单元格放置在曲面附近。因此，他们的计算和内存开销小了很多。另一方面，卷积仍在远离曲面进行，而曲面上的形状信息大部分都存在于曲面。另一种方法是仅沿网格的输入稀疏的活动体素集约束体积卷积的执行。

==我们的方法将此思想推广到高维多面体晶格卷积。与之前的工作相比，我们不需要将点预处理成为可能导致离散化伪影和表面信息丢失的体素。我们平滑地将输入表面信号映射到稀疏晶格，在这个晶格上执行卷积，并且平滑的将滤波器相应插值回输入曲面。此外，我们的架构可以很容易地将来自三维点云和渲染图像的特征表示合并到同一晶格中。==

##### 6.3.1.3  点云网络

Qi开创了另外的一种深度网络，能够直接在点云上运行。网络学习每个输入点的空间特征表示，然后通过最大池将点特征聚合到整个点集或分层曲面区域。由于没有明确考虑点的空间分布，这种聚合可能会丢失曲面信息。

##### 6.3.1.4 非欧几里得网络

另一种方式是将输入曲面表示为图形(例如多边形网格或基于点的连接图)，将图形转换为光谱表示，然后在光谱域中执行卷积。然后不同的形状往往有很大差距的光谱基础，因此导致泛化能力差。

* Yi等人提出的通过光谱变换器对齐形状基函数，但这需要一个稳健的初始化方法
* 另一种方法将输入形状嵌入二维参数域，然后在这些域内执行卷积，然而这些嵌入可能会受到空间扭曲的影响，或者需要拓扑一致的输入形状
* 其他方法将曲面参数化为局部面片，并在这些面片内执行基于曲面的卷积。

##### 6.3.1.5 联合2D-3D网络

FusionNet将形状分类得分与体积和多视点网络相结合，但这种融合发生在最后阶段，在这些网络的最终FC之后偶，并没有考虑他们的中间局部和全局特征表示。

#### 6.3.2双边卷积层BCL

在本节中，我们简要回顾BCL，其构成了SPLATNet中的基本构造块。在==Learning Sparse High Dimensional Filters: Image Filtering, Dense CRFs==中提出的BCL提供了一种在神经网络中加入稀疏高斯滤波的方法，在该文中，BCL被用作双边滤波的可学习推广，因此被称为==双边卷积层==。双边滤波涉及将给定2D图像投影到更高维的空间(例如由颜色和位置定义的空间)，传统上仅限于手工设计的滤波器内核。BCL为双边滤波提供个一种在高维空间中学习过滤核的方法。

##### 6.3.2.1 BCL的输入

假设F(R^n*d_f)为BCL给定的输入特征，其中n表示输入点的数量，df表示为每个点的输入特征的维数。对于三维点云，输入特征可以是低级特征，如颜色、位置等，也可以是高级特征，例如神经网络生成的特征。

BCL的一个特性是--它允许灵活地指定卷积操作所在的晶格空间，我们将其视为每个输入点的晶格特征。以L(R^n*dl)表示输入点处的晶格特征，dl表示卷积运算的特征空间的维数。==例如，晶格特征可以是位置和颜色定义的(XYZ RGB)这样的6维过滤空间。对于点云的标准3D空间过滤，L表示每个点的位置(XYZ)。因此，BCL获取输入点的输入特征F和晶格特征L，并且对这些点执行d_l维的滤波

##### 6.3.2.2 BCL的处理步骤

![image-20220427144227723](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144227723.png)

如上图所示，BCL有三个处理步骤，splat、convolve和slice：

* Splat：BCL首先通过重心插值将输入特征F投影到晶格特征L定义的d_l维晶格中。为提高效率，BCL使用了多面体晶格而非标准的欧式网格。晶格单形或网格点之间空间的大小通过缩放晶格特征 ΛL来控制，其中 Λ为d_l*d_l的缩放矩阵。
* Convolve：一旦输入点被投影到d_l维晶格中，BCL就会使用可学习的滤波器核对splat信号执行d_l维卷积。就像在标准的空间CNN中一样，BCL允许在d_l维空间中简单地指定过滤器的邻域
* slice：通过重心插值将滤波后的信号映射会输入点。产生的信号可以传递给其他BCL进行进一步的处理。这一步称为slice(切片)。BCL允许将滤波后的信号切片到输入点以外的另一组点上。从而可以指定一组不同的晶格特征L_out来获得m个输出点。

上述的三个操作可以写做矩阵乘法：

![image-20220427144248227](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144248227.png)

其中：Fc表示输入特征F的第c个通道，^Fc表示其对应的滤波信号。

##### 6.3.2.3BCL的特性

BCL的一些特性使其便于进行点云处理，例如：

* BCL的输入点在被投影到d_l维网格上时，不需要其有顺序或者在网格中(有一定的拓扑关系)
* BCL的输入和输出可以不同，因为BCL可以分别指定输入和输出的晶格特征L^in和L^out
* 由于BCL允许单独指定输入和晶格特征，因此可以将输入信号投影到不同维度的空间滤波。例如,2维图像可以投影到3维空间进行滤波
* 和标准的卷积一样，BCL可以很简单的指定滤波器邻域
* 由于信号在高维空间中往往是稀疏的，BCL使用哈希表对填充的顶点进行索引，且仅在这些位置进行卷积。这有助于处理稀疏输入

### 6.4 用于点云处理的SPLATNet_3D

我们首先介绍SPLATNet_3D,这是我们提出的网络结构中的一个实例，它直接在3D点云中运行，并且很容易适用于许多3D任务。

SPLATNet_3D的输入是一个3D点云P(R^n*d)，其中n为点的数量，d>=3为特征数量，一般包括点的坐标XYZ，其他特征通常可以直接从3D传感器中获取，如曲率颜色等。需要注意的是，网络中的第一个BCL的输入特征F和晶格特征L各自包含d特征维度的自己，df<=d,dl<=d。

作为输出，SPLATNet3D生成逐点预测，3D语义分割和3D部分分割任务是本框架适用的任务。使用诸如全局池化等简单地技术就能修改SPLATNet3D，从而生成单个输出向量，使其适用于分类的其他任务。

#### 6.4.1 网络结构

![image-20220427144301579](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144301579.png)

SPLATNet3D的网络结构如上。该网络从一个1X1的卷积层开始，然后是一系列的BCL。1X1卷积层分别处理每个输入点，不进行任何数据聚合。对于SPLATNet3D，我们使用T个BCL，每个BCL在三维晶格(dl=3)上运行，该晶格使用3D点位置XYZ作为晶格特征，Lin=Lout(R^n*3)。我们注意到不同的BCL可以使用不同的晶格尺度Λ。Λ是一个对焦矩阵，控制晶格中网格点之间的间距。对于SPLATNet3D中的BCL，我们沿X、Y、Z方向使用相同的晶格尺度，即Λ = λI3。其中λ是标量，I3表示3X3的单位矩阵。从第一个BCL的初始晶格尺度λ0开始，然后将晶格尺度除以因子2（(λt = λt−1/2)得到下一个晶格尺度 λt-1。也就是说，有T个BCL模块的SPLATNet3D使用以下的晶格标准(Λ0,Λ0/2,....,Λ0/2^T-1)。较低的晶格尺度意味着较粗的晶格和较大的过滤感受野。

因此，在SPLATNet3D中，与前期层相比，较深的BCL在输入点之间具有更长的联通性（即视野域更大，看到更多的点）。与标准CNN一样,SPLATNet3D允许对过滤器进行简单地规范。

串联T个BCL的响应，然后通过另外两个1X1卷积层。最后,softmax层生成逐点类标签概率。级联操作聚合了在不同晶格尺度尺度下运行的BCL的信息。将多个不同深度的网络层输出连接起来的类似技术在2D-CNN中非常游泳。除最后一个卷积层外，所有参数层图层后面都有Relu和BatchNorm。

#### 6.4.2 晶格空间及其尺度

在SPLATNet中使用BCL可以通过晶格特征轻松指定晶格空间，也可以通过缩放矩阵指定晶格尺度。改变晶格尺度Λ可以直接影响卷积运算所依据的信号的分辨率。这使我们能够直接控制网络层的感受野。

![image-20220427144320929](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144320929.png)

上图展示了不同晶格空间和比例的晶格单元可视化。==使用较大的晶格可以增加BCL感受野，另一种方式是通过增加其邻域大小==。但是在高维情况下，这将显著增加滤波器参数的数量。

我们观察到，在网络前期使用更小的晶格(更高的晶格分辨率)是有益的，然后使用更大的晶格(更低的晶格分辨率)深入网络。这与2D CNN中的常识一致；通过网络逐渐增加感受野有助于构建具有不同空间范围和抽象级别的层次表示。虽然我们在这项工作主要使用XYZ晶格进行实验，但BCL允许使用其他晶格空间，例如位置和颜色空间或法线空间。使用不同的晶格空间可以在输入点之间实施不同的连接，这可能对任务有益。

## 7：SO-Net 

### 7.1 摘要

本文提出了一种适用于无序点云深度学习的置换不变结构SO-net。SO-Net通过构建自组织地图(self-organizing map, SOM)对点云的空间分布进行建模。SO-Net基于SOM对单个点和SOM节点进行分层特征提取，最终以单个特征向量表示输入点云。网络的接收域可以通过节点的k近邻搜索来调节。在点云重建、分类、目标部分分割和形状检索等识别任务中，我们提出的网络的性能与最先进的方法相似，甚至更好。此外，由于提出的体系结构的并行性和简单性，训练速度明显快于现有的点云识别网络。

### 7.2：介绍

#### 7.2.1： 基于体素的

OcNet和Kd-Net

#### 7.2.2： 基于点云的

pointNet,pointNet++,Kd-Net

pointNet++==解决了pointNet中无法充分处理局部特征提取的问题，构建了一种类似金字塔的特征聚合方案，但其中的点采样和分组策略并没有揭示输入点云的空间分布==。Kd-Net明确地利用了点云的空间分布，但存在一些局限性，如缺乏重叠的感受野。

#### 7.2.3: SO-Net

在本文中，我们提出了SO-Net来解决现有的基于点云的网络中存在的问题。通过构造SOM对输入点云的空间分布进行建模，实现了对单个点和SOM节点的分层特征提取。最终，输入点云可以被压缩为单个特征向量。在特征聚合过程中，通过对SOM进行点对节点k近邻搜索来控制感受野重叠。通过网络设计和我们的置换不变SOM训练，从理论上保证了SO-Net对输入点顺序的不变性。我们的SO-Net应用包括基于点云的分类、自编码重构、部分分割和形状检索，如下图所示

![image-20220427144354614](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144354614.png)

* 我们设计了一个具有置换不变性的完了过SO-NET，明确利用了点云的空间分布。
* 利用SOM上的点对节点进行kNN搜索，通过系统可调的感受野重叠进行分层特征提取
* 我们提出了一个点云自编码器作为预训练，从而提高网络在各种任务中的性能。
* 与最先进的方法相比，在各种应用程序以更快的训练速度实现了类似或更好的性能，

### 7.3: 相关工作

与OcNet和Kd-Net不同，pointNet和PointNet++没有显式建模点的空间分布，而本文的SO-Net则解决了这个问题，在层次特征提取过程中显式的建模输入点云的空间分布，此外，可调的感受野重叠会使得局部特征更有效的聚合。

### 7.4 Self-Organizing Network

输入网络的点集记为P（p~i~<R^3^,i=0,....N-1）,按照==3.1==将其处理为M个SOM节点S(s~j~<R^3^,j=0,...,M-1)。按照==3.2==中单个点特征被最大池化为M个节点特征，这些节点特征可以进一步聚合为一个全局特征向量。SO-Net可以应用于各种计算机视觉任务，如分类、分割和点云重建等。

#### 7.4.1   置换不变性SOM

SOM用于生成低维的输入点云表示。我们构造了一个大小为m*m的的SOM，其中m（5，11），即节点在25，121之间。相对于深度网络中常用的反向传播算法，SOM采用无监督竞争学习进行训练。然而，朴素的SOM训练方案并非置换不变的，原因有二：

* 训练结果与初始节点高度相
* 每个样本的更新规则依赖于输入点的顺序

第一个问题通过为任意给定的SOM配置分配固定的初始节点来解决，由于输入点云在三个轴上都被归一化为[-1,1]范围内，我们通过将节点均匀地分散在一个单位球内生成一个合适的初始猜测，如下图(a)所示，类似于势场这样的简单方法可以用来构造这样一个均匀的初始猜测。

![image-20220427144410296](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144410296.png)

为解决第二个问题，我们并非每个点就更新一次节点，而是在累积了所有节点的影响后执行一次更新。批量更新的优点另一个优点是它可以作为矩阵操作来实现，在GPU上运行高效。

#### 7.4.2  编码器结构

![image-20220427144558970](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144558970.png)

如上图所示，SOM是分层特征提取的向导，也是系统调整感受野重叠的工具。给定SOM的输出，我们对每个点p~i~在SOM节点S上搜索k个最近邻(kNN),即点对节点kNN搜索：

![image-20220427144505580](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144505580.png)

然后通过与相关节点相减，将每个p~i~归一化为k个点：

![image-20220427144517485](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144517485.png)

将得到kN归一化转发到一系列全连接层中，提取单独的点特征。在每一层l上都有一个共享的全连接层，其中φ是非线性激活函数。l的输出如下：

![image-20220427144529615](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144529615.png)

第一层的p^0^~ik~可以简单的是归一化的点坐标p~ik~，或是坐标与其他特征的组合，比如表面的法向量。节点提取特征首先是通过上述kNN关联将kN点特则最大池化为M个节点特征。我们应用一个基于通道的最大池化操作来获得与相同节点s~j~相关联的点特征的节点特征s^0^~j~：

![image-20220427144540730](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144540730.png)

由于每个点根据点到节点的kNN搜索被归一化为k个坐标，因此可以保证M最大池化的操作的感受野是重叠的。具体来说，M个节点覆盖kN个归一化点。K为可调参数，用于控制重叠。由上述最大池化操作产生的每个节点特性进一步与相关的SOM节点相接。将M个增强节点特征转发到一系列共享层，然后聚合成代表输入点云的特征向量。

==特征聚合为点云的分离和组合==

SOM特征提取和节点拼接背后有一个直观的原因：

* 由于第一层的输入点都是用M个SOM节点进行归一化的，因此实际上被分离成M个微型点云，如上图所示。每个迷你点云在一个坐标中包含少量的点，其原点是相关的SOM节点。对于一个2048大小的点云，M=64，k=3,一个典型的迷你点云可能由x,y,z<(-0.3,0.3)内大约90个点组成。微型点云中点的数量和覆盖由SOM训练和KNN搜索决定。即M和k

第一批全连接层可以看作是对这些卫星点云进行编码的小pointNet。与SOM节点连接起到了将这些小点云组装成原始点云的作用。由于SOM显式的解释了输入点云的空间分布，我们的separate and assemble(分离-组装过程)比PointNet++中使用的分组更有效，

==置换不变性==

在SO-Net中有两个层次的特征聚合，从点特征到节点特征，从节点特征到全局特征向量。第一阶段将共享的PointNet应用到M个迷你点云中。这M个微型点云的生成与输入点的顺序无关，因为SOM训练和kNN的搜索是确定性，是通过空间关系而非输入顺序确定的。PointNet也拥有置换不变性，因此，从理论上保证节点特征和全局特征向量具有置换不变性。

==次优SOM训练的效果==

SOM的训练可能收敛到输入点云覆盖范围之外的孤立节点的局部最小值。在某些情况下，在点到节点的kNN搜索中，孤立的节点没有关联点，我们将对应的节点特征设为0.这种现象很常见，因为初始节点均匀地分布在一个单位球中，而输入点云可能只占据一个小角落。尽管存在次优SOM，SO-Net在对象分类中的性能仍然优于最先进的方法。

==卷积网络的探索==

值得注意的是，节点特征提取生成了一个类似图像的特征矩阵，他与输入点的顺序是不变的。可以采用标准的ConvNets进一步融合感受野增加的节点特征。然而在实验中采用二维卷积和池化替换第二批次的MLP，得到的分类精度有所下降。

## 8：Kd-Network

### 8.1 摘要

我们提出了一种新的深度学习结构(Kdnetwork)，用于3D模型识别任务和非结构化点云的任务。新的体系结构执行乘法转换，并根据kdtree强加给它们的点云的细分共享这些转换的参数。与目前主流的卷积架构不同(通常需要在均匀的二维或三维网格上进行栅格化)不同，kd-Net不依赖这种形式，从而避免了不良的缩放行为。

### 8.2 介绍

在这项工作中，我们选择了一种最常见的3D索引结构，并设计了Kd-Net，该架构在许多方面模仿卷积神经网络，但是使用Kd-tree结构来形成计算图，以共享可学习的参数，以前馈自底向上的方式计算一个层次表示序列。与统一体素网格相比，Kd-Net在训练和测试时占用更小的内存，并且计算更高效，这是因为Kd-Tree在索引和构造3D数据方面的能力得到了提高。

### 8.3 相关工作

### 8.4 使用Kd-Network进行三维重建

我们现在介绍Kd-Network，首先讨论其输入格式(一定大小的kd-Tree)，然后讨论每个Kd-Network表示的自底向上的计算，最后讨论了监督参数学习。

#### 8.4.1输入

Kd-Network以3D点云构建的Kd-Tree为基础进行工作。Kd-Network还可以考虑和利用已知的单个输入点的属性，如法线方向、反射率、颜色等。在训练时，Kd-Network工作于大小固定的点云N=2^D^(不同大小的点云可以通过降采样或过采样到这个大小)。选取点坐标范围(跨度)最大的坐标轴，将点集分为两个大小相等的子集，然后对每个子集进行递归，采用自顶向下的递归方式构建kd树。==最后得到一个深度为D的均衡kd-tree，其中包含N-1=2^D^-1个非叶节点。==

![image-20220427144635812](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144635812.png)割位置T~i~,每个叶节点中包含一个点云中的点。(假设平衡树上的每个非叶节点i的左右子节点的序号为*c*1(*i*)=2*i*,*c*2(*i*)=2*i*+1)

==上图中8~15为原始的输入点云，每两个点分为一组，以某个轴划分他们。==

==从根节点到叶节点对KD树的每个节点进行编号，根节点为0，往后递增；==

==最右边的0好节点可以看作是输出的类别预测v0,==

==从左到右，可以看做这个kd-network的特征前向传播的方向==

==图中的圆圈表示的是特征传播并聚合的过程，对应卷积核，其参数是可以学习的，相同的颜色表示共享参数，即如果在相同的维度对点集进行划分，认为其卷积参数也应该共享==

#### 8.4.2 使用Kd-Network进行数据处理

给定一个输入kd-tree T，一个预训练的kd-network计算与树的每个节点相关联的向量表示v~i~，每个叶节点用k一个k维的向量来表示，每个非叶子节点由自上而下的计算得到，对于位于第l层的第i个节点

![image-20220427144651783](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144651783.png)

或者简短的表示为:

![image-20220427144700859](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144700859.png)

其中ϕ ( ⋅ )是一个非线性函数，[ ]表示连接，w^li^~dj~为l~i~层学习到的参数

矩阵的维度由树的每一层表示的维度m^1^,m^2^,m^D^决定，如第l层的矩阵W^l^~x~,W^l^~y~,W^l^~z~大小为m^l^*2m^l+1^，偏执向量b^l^~x~,b^l^~y~,b^l^~z~的维度为m^l^，通过自下而上的方式，可由叶节点计算得到root节点v1(T),然后可以通过各类线性或者非线性的变换来对v1(T)进行处理

#### 8.4.3 分类学习

Kd-network是一种前馈神经网络，D-1个非叶子节点都有有可学习的参数{W jx , W jy , W jz , bjx, bjy, bjz}，同样最后的分类器也有可学习的参数{W 0, b0} 。标准的反向传播可以用于计算网络参数的损失函数梯度，因此，可以使用标准的随机优化算法和标准损失函数学习网络参数。

#### 8.4.4 检索学习

学习形状是也很简单的，它可以不产生类的概率，而是产生具有特定维数的描述符向量，该向量表示形状可以用于检索。然后可以使用反向传播来学习kd-network的参数，使用任何嵌入学习损失来观察匹配和非匹配形状的粒子。

#### 8.4.5 kd-network的属性

* 层级的参数共享：与卷积网络类似，kd-network也在kd-tree的钱l层所有节点上使用共享{W jx , W jy , W jz , bjx, bjy, bjz}参数的乘法。
* 分层级的表示：kd-network也使用类似于卷积网络的层次化的感受野，唯一不同的就是kd-network同一层的感受野是不重叠的。
* 扰动的部分不变性：因为主要的前向传播操作忽略了分裂阈值，输入点的任何小的空间扰动只能通过叶子节点表示来影响kd-network的输出
* 旋转不变性：与卷积网络类似，kd-network具有旋转不变性
* kd-tree结构的作用：底层的kd-tree决定哪些叶子表示被组合在一起，以及按照什么顺序组合。底层kd-tree结构可以看作是一个形状描述符本身，因此无论叶子表示是什么，他都是信息的来源。（即使是没有任何意义的节点，他都作为表现形状的一部分起作用）

![image-20220427144729726](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144729726.png)

#### 8.4.6 分割的拓展

受卷积神经网络应用于图像语义分割的启发，

kd-networks模仿设计了跳跃连接的encoder-decoder结构。在计算得到v~i~后在每个节点i处计算向量vi！。vi！的计算通过设置vi!=vi（或通过一个或多个全连接层获得）进行，然后自上而下的计算

![image-20220427144740326](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427144740326.png)

为了增加模型的容量，可以在架构的开始或架构的末尾插入额外的与非线性交织的倍增层(通过在叶子上共享参数使这些层类似于ConvNets中的1×1-convolutions)。此外，还可以在瓶颈处插入全连接的倍增层

==上图为分隔网络的示意图，这里的分割网络可以看作是两个Kd-tree拼接在了一起，左半边与分类网络和检索网络结构一样，是encoder,右半边为decoder，也就是倒过来的Kd-Tree，将根节点的特征传播到所有的叶节点上，设右半部分的kd-tree的根节点为v1,而节点i上的特征向量为vi，特征传播时的更新公式如下：==

![image-20220427151646458](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20220427151646458.png)



### 8.4 进一步解释

* 要解决的问题：3D点云识别任务
* 解决的方法：参考了kd-tree的结构，提出了一种新的树形结构的神经网络，用于处理不规则的点云数据
* 仍然存在的问题：如果点云存在旋转，那么kd-tree在X/Y/Z轴方向进行切分时会得到不同的结果，影响最终的效果(只有平移不变性，无旋转不变性，因此不具备完全的置换不变性)
* 每次网络做前向操作，都需要现将输入的点云转为kd-tree，预处理必须要占用一定的时间

## 9：基于子流形系数卷积网络的三维语义分割

### 9.1：摘要

我们引入了新的稀疏卷积运算，旨在更有效地处理空间稀疏数据，并使用他们开发空间稀疏卷积网络。

### 9.2 介绍

维度灾难在三维或更高维的数据上体现的尤为明显，网格上的点数随维度呈指数增长。在这种情况下，尽可能利用数据稀疏性以减少数据处理所需的计算资源变得越来越重要。

以往的卷积网络的稀疏实现的缺点之一是，他们通过应用"完整"卷积来"拓展"每一层中的稀疏数据。==而在本网络结构中，我们证明了创建在整个网络中保持相同稀疏度的卷积网络是可行的。因此，训练具有更多层次的网络变得切实可行==

我们提出了一种用于执行系数卷积(SCs)的新实现，并引入了一种称为子流形系数卷积(SSC)的新卷积算子。我们使用这些算子作为子流形系数卷积网络(SSCN)的基础，这些网络针对3D点云的有效语义分隔进行优化。

### 9.3 相关工作

以往的关于系数卷积的工作实现了一个卷积算子，该算子增加了每层的活动站点数量，在[4]中，所有的至少有一个"活动"输入站点的站点都被认为是活动的;在[3]中，一个更大等级的稀疏性，是通过使用ReLUs和一个特殊的损失函数来计算卷积的。相比之下，我们引入了子流形稀疏卷积来固定活性位点的位置，从而使得许多层的稀疏性保持不变。我们证明，这使得训练类似于VGG和ResNet的深度较深、效率较高的网络变得切实可行，并且非常适合于点云语义分割任务。

本网络相较于OctNet不需要再空区域上进行计算。

### 9.4 卷积网络的空间稀疏性

我们将d维卷积网络定义为以(d+1)维张量作为输入的网络。输入张量中包含d个时空维度（如长度、宽度、高度、时间等）和一个额外的特征空间维度（如RGB颜色通道或表面法向量）。输入对应于站点的d维网络，每个站点都与一个特征向量相关联。如果特征向量中的任何元素不处于基态，比如他是非零的，我们就将输入中的一个站点定义为活动的。如果数据不是自然稀疏的，则可以使用阈值来消除特征向量与基态之间距离很小的输入点。==请注意，即使输入张量是(d+1)维的，活动也是一种d维现象；沿特征维的整条线只要活动和不活动两种状态==

类似的，d维卷积网络的隐藏层由特征空间向量的d维网格表示。当通过网络传播输入数据时，如果作为输入的层中的任何站点处于活动状态，则隐藏层中的站点处于活动状态。（==请注意，当使用大小为3的卷积时，每个站点都连接到下面隐藏层中3^d^站点==）因此，隐藏层中的活动遵守归纳定义，其中每一层确定下一层中的活动状态集。在每个隐藏层中，非活动站点都具有相同的特征向量，对应于基态的特征向量。在训练时，每次前向传播只需要计算一次基态值，在测试时，所有向前传播一次基态值。这就大大节省了计算和内存使用。

我们认为，上述框架限制过度，尤其是因为没有修改卷积运算以适应输入数据的稀疏性。如果输入数据包含单个活动站点，则在应用3d卷积后，将存在3d活动站点。应用



## 7：深度学习在3D点云处理中的探索

### 7.1：绪论

#### 7.1.1 三维物体的表达形式

三维形状的表现方法可以有多种，比如这种多种投影的，变为体素的，基于网格(使用GNN，发展刚开始，可以看后续发展)，或者基于RGB-D图像的CNN网络，或者直接基于点云的深度学习，可以是CNN的也可以是GNN的

![image-20211221141914051](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221141914051.png)

#### 7.1.2 点云的作为一种表达形式的优点和应用范围

老生常谈的问题，点云作为三维表现的方法具有三个优点：

* 是传感器得到的原始数据
* 是很容易进行表示的，一个有N个点的点云数据就是一个N维的矩阵
* 能够很好的表达三维形状特征

在多个领域中，这种表示方法也得到了广泛的应用

![image-20211221142110922](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221142110922.png)

#### 7.1.3 点云结合深度学习要解决的问题有哪些？

![image-20211221143058520](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221143058520.png)

#### 7.1.4 点云数据集

| 数据集         | 场景 | 使用点数 | 任务      |
| -------------- | ---- | -------- | --------- |
| ModelNet40     | 模型 | 1k       | 分类      |
| ShapeNet Part  | 模型 | 2k       | 部分分割  |
| PartNet Models | 模型 |          | 部分分割  |
| S3Dis          | 室内 | 8k       | 语义分割  |
| Semantic 3D    | 室外 | 4m       |           |
| ScanNet        | 室内 |          | 分割/检测 |
| Kitti/nuScenes | 室外 |          | 检测      |

![image-20211221143145771](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221143145771.png)

![image-20211221143350750](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221143350750.png)

#### 7.1.5 点云深度学习面临的挑战

使用点云进行深度学习面临着以下的问题：

* 不像是二维图像那样有很好的拓扑性质，点云的分布有可能不同，或者分布相同但是顺序不同，这都使得卷积操作不能直接应用到点云的深度学习中
* 而且针对于model这种toy的数据，存在一个刚性变换的问题，网络是否能对这种刚性变换有鲁棒性呢？
* 对于点的缺失、外围点outlier、噪声、只有部分的数据如何保持鲁棒性？大规模的数据要怎么处理才能保持高效？

![image-20211221144457371](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221144457371.png)

### 7.2 相关工作

#### 7.2.1 PointNet family

![image-20211221145105119](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221145105119.png)



![image-20211221145414190](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221145414190.png)

#### 7.2.2 regulat processing

我们想要在深度学习中尽量得到端到端的网络，因此前期的regular的工作并无法满足这个要求，这里有pointCNN可以使用这种思想设计端到端的网络结构。

也可以使用二维中的SIFT算子，来获得方向的编码和尺度的信息。

![image-20211221145717435](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221145717435.png)



![image-20211221150045178](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221150045178.png)

#### 7.2.3 graph-based modeling

![image-20211221150848866](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221150848866.png)

![image-20211221151233998](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221151233998.png)

#### 7.2.4 convolution kernal

![image-20211221151511085](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221151511085.png)





![image-20211221152155490](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221152155490.png)

  ![image-20211221152519345](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221152519345.png)

#### 7.2.5 Robustness

![image-20211221152849670](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221152849670.png)

![image-20211221153034463](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221153034463.png)

### 7.3 Relation-Shape CNN

对于2D图像，如果我们将其RGB信息去除掉，就无法检测出目标了，因此我们认为2D图像的信息来源于RGB信息。

而对于3D点云，如果我们将RGB信息出去掉，其实是对目标检测没有影响的，因此我们认为点云的信息来源于空间分布。

以下图中简单图形为例，我们认为点是有一点关联的，单独去学习一个点是不合理的，即点之间有dependences，如果我们假设每个点都有关联，就会稍显复杂了，因此，我们就假设中心点与其他所有点都有关联，我们以中心点为参考点，来找其他点与中心点的relation，对这个relation进行学习，然后我们对局部的点云的relation进行一个聚合，最后得到一个shape的表示。

![image-20211221153407533](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221153407533.png)

为满足置换不变性，我们要求聚合函数A是对称的，类似于PointNet中的max pooling，T函数是在学习中的weight是共享的，否则输入排列发生了变化，置换不变性就不满足了。

而传统的卷积操作主要有两个缺点：

* 权重是不共享的
* 梯度只是针对于单个点的

因此我们打破这样的思维，不再是学习点，而是学习点中间的关系，即relation，这里的权重不再是单个点的，而是点x~i~和点x~j~的了。我们想要这个关系从几何空间中来，并且是一种几何的关系去学习这样的表达，以此进行卷积操作。我们将一个低维的关系通过多层感知机将其映射到高维空间中去。以此来做一个这样的卷积操作。

![image-20211221160049393](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221160049393.png)

![image-20211221161119453](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221161119453.png)

我们的网络对于旋转具有较好的鲁棒性，因为我们学习了点之间的关系这样的特征，而这些特征是不会随着旋转发生变化的。

![image-20211221161432983](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221161432983.png)

![image-20211221161759396](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221161759396.png)

针对于置换不变性，我们主要是通过学习关系来使网络对旋转更有鲁棒性的，而针对于输入，我们引入了法线信息用于构建局部坐标系。

![image-20211221162403629](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221162403629.png)

### 7.4 DensePoint

我们知道，在二维图像中，只有一块小区域，是没有意义的，我们需要多个尺度的信息，从而得到双向txture。同样的，在点云中也是这样的，我们也会学习多个尺度的特征，比如PointNet++中使用的MSG和MAG，学习多个尺度的特征后进行拼接，但是这样的操作复杂度很高：

* 如果不共享参数，则会导致模型的参数很多
* 如果共享参数，则会导致FLOPS很高
* 尺度也不能太多，3~5个尺度是常用的
* 一般我们认为，多个尺度是在不同的卷积层上做的，尺度的尺寸越大，包含的信息就越多，对于点云就是semantic level越高，但是事实上，这种尺度变换并没有这样的特性



![image-20211221163907693](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221163907693.png)

这样我们就实现了一种多级的卷积

![image-20211221164159882](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221164159882.png)

![image-20211221164410942](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221164410942.png)

![image-20211221164428487](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221164428487.png)

对于噪声的鲁棒性极好，不需要数据增强

![image-20211221164516677](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221164516677.png)

### 7.5 Outlook

点云深度学习需要解决的问题(蓝色)

![image-20211221164918790](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211221164918790.png)









# 三维多目标检测

## 5：多目标检测

### 5.1 相关工作

解决3D物体检测的三种方向：

![image-20211213162752792](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211213162752792.png)

* 使用2D图像直接得到3D的检测框
* 将3D对象压缩成为2D对象然后去做检测
* 由于传感器获取的只是表面的数据，则是否可以得到一种检测器，只关心表面的数据，从而大大减少计算量

#### 5.1.1 Frustum PointNets

* 使用2D得到3D包围框的精度还是太低，因此我们想要使用RGBD相机得到更好的效果

![image-20211213163302387](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211213163302387.png)

我们利用RGB图片的高分辨率和丰富的纹理，结合雷达点云准确的深度信息和3D形状、位置和大小。

![image-20211213163519786](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211213163519786.png)

 我们先在图片中识别出对象，而这个对象只可能存在在这个Frustum中，那我们就可以锁定在这个视锥中去搜索这个物体的位置和形状，则我们将视锥中的点云提取出来，通过一些3D的网络来regress(回归)bounding box。

![image-20211213170547304](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211213170547304.png)

(1)通过2D来proposal

(2)去掉一些干扰点,是一个Instance Segmentation的问题

(3)这里我们使用点云来进行segmentation，因为使用2D进行segmentation进行回归的时候因为缺乏深度信息，会在3D中得到很远的点，但是如果使用点云，则会有效减少这些点，使得点在一个更可控的区间内。

![image-20211213193329125](C:\Users\gavin\AppData\Roaming\Typora\typora-user-images\image-20211213193329125.png)

实验证明，使用PointNet比起CNN的效果要优越特别多。

缺点：

(1)强依赖于2D检测的结果：如果在2D中没有检测到，则3D会忽略这个点

(2)不能在视锥中同时检测多个物体

#### 5.1.2 Multi-View 3D Object Detection Network

#### 5.1.3 VoxelNet

#### 5.1.4 PointPillars



















 









